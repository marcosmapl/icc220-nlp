{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84e696d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171532d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Laboratório de Modelos de Linguagem\n",
    "\n",
    "## Prof. André Carvalho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b17f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementando Modelos de Linguagem Probabilisticos\n",
    "\n",
    "Hoje vamos ver o passo a passo da implementação de um modelo de linguagem baseado em trigramas, com smoothing de Laplace.\n",
    "\n",
    "Como sempre em NLP, vamos começar pegando um corpus e pre-processar.\n",
    "\n",
    "Usaremos o corpus do machado, mas não apenas Dom Casmurro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd84a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def limpa(raw):\n",
    "    return [re.sub('\\W+\\s*', ' ',i).lstrip() for i in raw.lower().split('.') if i != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad4c39d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#limpa(\"Testando, a limpeza. O que será que ela faz? 1.2 vai separar ou não?\")\n",
    "\n",
    "print(nltk.corpus.machado.readme())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df22b71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "s = nltk.corpus.machado.readme()\n",
    "livros = re.findall(r\"(\\w+\\/\\w+\\.txt):\",s)\n",
    "corpus = []\n",
    "for t in livros:\n",
    "    raw = nltk.corpus.machado.raw(t)\n",
    "    corpus+= limpa(raw)\n",
    "    \n",
    "for i in range(len(corpus)):\n",
    "    corpus[i] = '<s> '+corpus[i]+' </s>'\n",
    "print(corpus[200],len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffa6f7f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vamos agora fazer uma função que recebe um corpus como uma lista  e retorna um vocabulário com todos os tokens com frequência maior que `freq`.\n",
    "\n",
    "Ele vai ser um dicionário tendo como chave o termo e valor a frequência (vai facilitar).\n",
    "\n",
    "Pode usar Counter no lugar do dicionário também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a479ad",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def vocabularioFixo(corpus,freq):\n",
    "    tk = nltk.tokenize.WhitespaceTokenizer()\n",
    "    tokens = tk.tokenize(' '.join(corpus))\n",
    "    freqs = nltk.FreqDist(tokens)\n",
    "    voc = {i[0]:i[1] for i in freqs.items() if i[1]>=freq}\n",
    "    unk = sum([i[1] for i in freqs.items() if i[1]<freq])\n",
    "    voc['<UNK>'] = unk\n",
    "    return voc\n",
    "\n",
    "voc = vocabularioFixo(corpus,10)\n",
    "\n",
    "#print(voc['<UNK>'])\n",
    "print(corpus[0:10],vocabularioFixo(corpus[0:10],2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b949671",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "De posse do vocabulário, agora é hora de gerar os unigramas e suas probabilidades.\n",
    "\n",
    "Lembrando, a probabilidade de um unigrama é:\n",
    "\n",
    "$$ P(w_i) = \\frac{freq(w_i)}{tottokens} $$\n",
    "\n",
    "Palavras fora do vocabulário __devem__ ser contadas, mas devem ficar na probabilidade de `UNK`. Vamos modificar o vocabulário anterior para contar os `UNK`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b849cff",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def unigrama(corpus,vocabulario):\n",
    "    # O vocabulário já tem as frequencias\n",
    "    freqtot = sum(vocabulario.values())\n",
    "    return {x:vocabulario[x]/freqtot for x in vocabulario.keys()}\n",
    "\n",
    "modeluni = unigrama(corpus[0:10],voc)\n",
    "modeluni\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd8362",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vamos agora fazer um modelo de bigramas baseado neste mesmo vocabulário.\n",
    "\n",
    "Lembrando:\n",
    "\n",
    "$$P(w_i|w_{i-1}) = \\frac{f(w_{i-1},w_{i})}{f(w_{i-1})} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbee3e9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def bigrama(corpus,vocabulario):\n",
    "    bigramas = Counter()\n",
    "    for s in corpus:\n",
    "        tk = nltk.tokenize.WhitespaceTokenizer()\n",
    "        tokens = tk.tokenize(s)\n",
    "        big = list(nltk.bigrams(tokens))\n",
    "        for i in range(len(big)):\n",
    "            if big[i][0] not in vocabulario:\n",
    "                big[i] = ('<UNK>',big[i][1])\n",
    "            elif big[i][1] not in vocabulario:\n",
    "                big[i] = (big[i][0],'<UNK>')\n",
    "        bigramas.update(big)\n",
    "    return {x:bigramas[x]/vocabulario[x[0]] for x in bigramas}\n",
    "            \n",
    "        \n",
    "bigrama(corpus,voc)[('dom','casmurro')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3df56e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esse modelo está sem smoothing.\n",
    "\n",
    "Vamos modificar ele para receber um $\\lambda$ que vai representar o quanto de frequencia vai ser adicionado a todos os bigramas.\n",
    "\n",
    "Se este valor for 1, vai ser o que vimos na aula passada. Mas podemos colocar mais baixo. Então fica:\n",
    "\n",
    "$$ P_l(w_i|w_{i-1}) = \\frac{f(w_i|w_{i-1})+\\lambda}{f(w_{i-1})+|V|\\lambda} $$\n",
    "\n",
    "Vamos fazer uma função que retorna a probabilidade de um bigrama nunca antes visto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec1c46",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def bigrama(corpus,vocabulario,lamb=0.01):\n",
    "    bigramas = Counter()\n",
    "    for s in corpus:\n",
    "        tk = nltk.tokenize.WhitespaceTokenizer()\n",
    "        tokens = tk.tokenize(s)\n",
    "        big = list(nltk.bigrams(tokens))\n",
    "        for i in range(len(big)):\n",
    "            lbig = list(big[i])\n",
    "            if lbig[0] not in vocabulario:\n",
    "                lbig[0] = '<UNK>'\n",
    "            if lbig[1] not in vocabulario:\n",
    "                lbig[1] = '<UNK>'\n",
    "            big[i] = tuple(lbig)\n",
    "        bigramas.update(big)\n",
    "    probs = {}\n",
    "    bigramas = dict(bigramas)\n",
    "    for x in bigramas:\n",
    "        if x[0] not in probs:\n",
    "            probs[x[0]]= {}\n",
    "        probs[x[0]][x[1]] = (bigramas[x]+lamb)/(vocabulario[x[0]]+len(vocabulario)*lamb)\n",
    "                \n",
    "    return probs,bigramas\n",
    "\n",
    "modelbig, freqbig = bigrama(corpus,voc,0.01)\n",
    "print(modelbig['dom'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980acf9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Também precisamos de uma função para calcular a probabilidade residual dos bigramas que nunca foram vistos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d964a80",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    " \n",
    "def bigramadesc(big,vocabulario,lamb):\n",
    "    return lamb/(vocabulario[big[0]]+len(vocabulario)*lamb)\n",
    "\n",
    "\n",
    "\n",
    "bigramadesc('dom',voc,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef19af9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vamos agora implementar o modelo de trigramas.\n",
    "\n",
    "Para trigramas podemos usar uma função built-in da NLTK, `trigrams`, ou uma função genérica `ngrams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb72620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigrama(corpus,vocabulario,freqbig,lamb=0.01):\n",
    "    trigramas = Counter()\n",
    "    for s in corpus:\n",
    "        tk = nltk.tokenize.WhitespaceTokenizer()\n",
    "        tokens = tk.tokenize(s)\n",
    "        tri = list(nltk.trigrams(tokens))\n",
    "        for i in range(len(tri)):\n",
    "            ltri = list(tri[i])\n",
    "            for j in range(len(ltri)):\n",
    "                if ltri[j] not in vocabulario:\n",
    "                    ltri[j] = '<UNK>'\n",
    "            tri[i] = tuple(ltri)\n",
    "        trigramas.update(tri)\n",
    "    probs = {}\n",
    "    tregramas = dict(trigramas)\n",
    "    for x in trigramas:\n",
    "        if (x[0],x[1]) not in probs:\n",
    "            probs[(x[0],x[1])]= {}\n",
    "        probs[(x[0],x[1])][x[2]] = (trigramas[x]+lamb)/(freqbig[(x[0],x[1])]+len(vocabulario)*lamb)\n",
    "                \n",
    "    return probs,trigramas\n",
    "                \n",
    "    return probs\n",
    "modeltri,freqtri = trigrama(corpus,voc,freqbig,0.001)#[('rio','de','janeiro')]\n",
    "modeltri[('rio','de')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqbig[('rio','de')]\n",
    "#freqtri[('rio','de','janeiro')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891f4724",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "De posse do modelo, vamos fazer um gerador agora?\n",
    "\n",
    "Um gerador sequencial:\n",
    " - Gera um \\<s\\>\n",
    " - Procura por uma palavra inicial, sendo um bigrama começando por \\<s\\> + probabilidade unigrama da palavra.\n",
    " - A partir da segunda palavra, já usa unigrama+bigrama+trigrama\n",
    "    \n",
    "Vamos fazer um gerador de modelo de bigramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f5f42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#funcao q recebe uma distribuicao e escolhe um valor aleatoriamente seguindo a distribuicao\n",
    "def escolhe(dist):\n",
    "    prob = random.random()\n",
    "    v = 0\n",
    "    for i in dist:\n",
    "        v+=dist[i]\n",
    "        if(v>prob):\n",
    "            return dist[i],i\n",
    "    return dist[i],i\n",
    "\n",
    "def escolhaGulosa(dist):\n",
    "    r = max(dist,key=dist.get)\n",
    "    return dist[r],r\n",
    "\n",
    "def escolheTopk(dist,k):\n",
    "    prob = random.random()\n",
    "    v = 0\n",
    "    l = {x:dist[x] for x in sorted(dist, key=dist.get, reverse=True)[:k]}\n",
    "    topk = {x:l[x]/sum(l.values()) for x in l}\n",
    "    #gerar topk\n",
    "    for i in topk:\n",
    "        v+=topk[i]\n",
    "        if(v>prob):\n",
    "            return topk[i],i\n",
    "    return topk[i],i\n",
    "\n",
    "\n",
    "anterior = '<s>'\n",
    "_,atual = escolheTopk(modelbig[anterior],20)\n",
    "while(atual!='</s>'):\n",
    "    print(atual,end=' ')\n",
    "    _,nova = escolheTopk(modeltri[(anterior,atual)],20)\n",
    "    anterior = atual\n",
    "    atual = nova\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeebe20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vamos fazer agora um interpolando uni/bi com uma interpolação simples (0.9 pra bigrama, 0.1 pra unigrama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f774bb5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def escolhe(dist):\n",
    "    prob = random.random()\n",
    "    v = 0\n",
    "\n",
    "    for i in dist:\n",
    "        if(v>prob):\n",
    "            return dist[i],i\n",
    "        v+=dist[i]\n",
    "    return dist[i],i\n",
    "\n",
    "def gerador(modeluni,modelbi,modeltri,voc,lamb,lista = True):\n",
    "    saida = ['<s>']\n",
    "    probab = random.random()\n",
    "    dist = {x:modeluni[x]*0.1 + 0.9* bigramadesc(('<s>',x),voc,lamb) for x in modeluni}\n",
    "    dist.update({x:0.1*modeluni[x] + 0.9*modelbi['<s>'][x] for x in modelbi['<s>']})\n",
    "    print(sum(dist.values()))    \n",
    "    palavra = escolhe(dist)[1]\n",
    "    while(palavra!='</s>'):\n",
    "        print(palavra, end=' ')\n",
    "        dist = {x:modeluni[x]*0.1 + 0.9* bigramadesc((palavra,x),voc,lamb) for x in modeluni}\n",
    "        dist.update({x:0.1*modeluni[x] + 0.9*modelbi[palavra][x] for x in modelbi[palavra]})\n",
    "        palavra = escolhe(dist)[1]\n",
    "gerador(modeluni,modelbig,modeltri,voc,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff2bfe5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Computando a qualidade do modelo\n",
    "\n",
    "Vamos computar a perplexidade para ver a qualidade dos nossos modelos.\n",
    "\n",
    "Relembrando, a perplexidade é:\n",
    "\n",
    "$$ \\sqrt[N]{\\prod_{i=1}^{N}\\frac{1}{P(w_i|w_{i-k}...w_{i-1})}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0795a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexidade(probsent, N):\n",
    "    return 1/probsent**(1/N) # onde N eh o tamanho das distribuições do modelo/numero de tokens\n",
    "# Se for em espaco log, eh e^((-1/N)*soma(log P(w_i)))\n",
    "\n",
    "def probsent(modelo,corpus):\n",
    "    return \n",
    "\n",
    "def perplexidadeModelo(modelo,corpus):\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
